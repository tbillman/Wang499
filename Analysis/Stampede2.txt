#####Analysis of NPV results#####
####Have Shell Script go to Honors Directory#####
library("tidyverse")
library("randomForest")
library("car")
datas= read_csv(file = "OrgNPVs.csv")
# #Issue with spaces in Variable Names
# mod = lm(NPV ~ CreditScore + `MSA Code` + `MI Percentage` +
#            DTI + UPB + CLTV + LTV + `Interest Rate`  + `Original Term`, data)
# mod1 = lm(NPV ~ CreditScore + DTI + UPB + CLTV + LTV + State, data)
# cleandat = cbind(data$CreditScore,data$`MSA Code`, data$`MI Percentage`,
#                  data$`Number of Units`, data$`Occupancy Status`, data$CLTV,
#                  data$DTI, data$UPB, data$LTV, data$`Interest Rate`, 
#                  data$Product, data$State, data$`Postal Code`)
# rf1 = randomForest(cleandat[complete.cases(cleandat),], y= data$NPV[complete.cases(cleandat)])
#####Using Sample Data instead#####
#datas = read_csv(file = "C:/Users/Thomas/Documents/Github/Wang499/OrgSampleNPVs.csv")
datasu = sapply(1:length(colnames(datas)), function(x){
  dim(unique(datas[,x]))[1]
})
useless = which(datasu == 1)
datas = datas[,-useless]
keep = which(complete.cases(datas) == T)
datasc = datas[keep,]
modc = lm(NPV ~ CreditScore + `MSA Code` + `MI Percentage` +
            DTI + UPB + CLTV + LTV + `Interest Rate`  + `Original Term`, datasc)
outlc = which(cooks.distance(modc) >= (4/dim(datasc)[1]))
datascc = datasc[-outlc,]
#####Randomforest Exploratory#####
badvars <- c(5,16,18,19,22)
rfdat = datascc[,-badvars]
names(rfdat) = make.names(names(rfdat))
rfdat$FirstTimeHomebuyer = as.factor(rfdat$FirstTimeHomebuyer)
rfdat$Occupancy.Status = as.factor(rfdat$Occupancy.Status)
rfdat$Channel = as.factor(rfdat$Channel)
rfdat$PPM = as.factor(rfdat$PPM)
rfdat$Property.Type = as.factor(rfdat$Property.Type)
rfdat$Loan.Purpose = as.factor(rfdat$Loan.Purpose)
rfdat$Seller.Name = as.factor(rfdat$Seller.Name)
rfdat$Servicer.Name = as.factor(rfdat$Servicer.Name)
rf = randomForest(NPV ~. , data = rfdat)
rf
plot(rf)
train <- sample(ceiling(.8*dim(rfdat)[1]), 1:dim(rfdat)[1])
#mtry is no of Variables randomly chosen at each split
for(mtry in 1:8){
  rf=randomForest(NPV ~ . , data = rfdat,subset = train ,mtry=mtry,ntree=400) 
  oob.err[mtry] = rf$mse[400] #Error of all Trees fitted
  pred<-predict(rf,rfdat[-train,]) #Predictions on Test Set for each Tree
  test.err[mtry]= with(rfdat[-train,], mean( (NPV - pred)^2)) #Mean Squared Test Error
  
  cat(mtry," ") #printing the output to the console
}
test.err
oob.err
matplot(1:mtry , cbind(oob.err,test.err), pch=19 , col=c("red","blue"),type="b",ylab="Mean Squared Error",xlab="Number of Predictors Considered at each Split")
legend("topright",legend=c("Out of Bag Error","Test Error"),pch=19, col=c("red","blue"))
